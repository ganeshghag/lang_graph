{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd303476-d27d-4f5c-b2e1-ad3aff4ece32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Je aime le programmation.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-21T09:48:25.648872Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3822456200, 'load_duration': 1630869200, 'prompt_eval_count': 45, 'prompt_eval_duration': 1123000000, 'eval_count': 7, 'eval_duration': 435000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-aa6f892f-4c10-4aae-bc30-d9e024750cb4-0', usage_metadata={'input_tokens': 45, 'output_tokens': 7, 'total_tokens': 52})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install langchain-ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22bfcb27-e91e-43f7-b3cd-e670ffcad584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Je aime programmer.\\n\\n(Note: I used \"aime\" which is the correct verb conjugation for the present tense of \"aimer\", which means \"to like\". If you meant to say something else, please let me know and I\\'ll be happy to help!)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic chat invoke / chat interface supports sending message history into input messages\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33d9bbc3-1edc-43c7-9de6-98b79577e334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='आप प्रोग्रामिंग का बहुत शौकीन हैं। (aap programmining ke baht shaukini hain.)', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-21T10:01:51.6850801Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2992517500, 'load_duration': 47950400, 'prompt_eval_count': 40, 'prompt_eval_duration': 430000000, 'eval_count': 35, 'eval_duration': 2510000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-5404132a-d819-4dc2-8c6d-7bb4ca439f3c-0', usage_metadata={'input_tokens': 40, 'output_tokens': 35, 'total_tokens': 75})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with chat prompt\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "ai_msg = chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"Hindi\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "ai_msg\n",
    "#print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b101db31-3b8b-4cb9-b184-600656656ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'validate_user',\n",
       "  'args': {'addresses': ['123 Fake St', '234 Pretend Boulevard'],\n",
       "   'user_id': 123},\n",
       "  'id': '74515c72-adf7-418c-973a-8a822afbf939',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ollama with TOOL Calling\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "@tool\n",
    "def validate_user(user_id: int, addresses: List[str]) -> bool:\n",
    "    \"\"\"Validate user using historical addresses.\n",
    "\n",
    "    Args:\n",
    "        user_id (int): the user ID.\n",
    "        addresses (List[str]): Previous addresses as a list of strings.\n",
    "    \"\"\"\n",
    "    return True\n",
    "\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    ").bind_tools([validate_user])\n",
    "\n",
    "result = llm.invoke(\n",
    "    \"Could you validate user 123? They previously lived at \"\n",
    "    \"123 Fake St in Boston MA and 234 Pretend Boulevard in \"\n",
    "    \"Houston TX.\"\n",
    ")\n",
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6359bdc-09f3-4e62-9dcc-c78098bbbf18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
